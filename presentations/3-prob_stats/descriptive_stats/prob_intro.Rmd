---
output: html_document
---

# Definitions

- Probability: the branch of mathematics dealing with calculating the likelihood of an event's occurrence and the uncertainty involved 

- Statistics: the branch of mathematics related to collecting and analyzing numerical data for the purpose of making inferences and/or predictions about a population

- This lecture introduces the relationship between these areas - to accomplish this we'll need to explore the following concepts:

    + Experiment
    + Outcome
    + Sample space
    + Event
    + Borel Sigma-Algebra
    + Random Variable
    + Statistic

# Probability Concepts

## Experiment

- A scientific procedure undertaken to make a discovery, test a hypothesis, or demonstrate a known fact

    + When you hear the word experiment you may be think of scientists in lab coats or remember your experiences in a Chemistry class

    + While these are accurate representations of an experiment, I'd like for you to think more broadly - <red>think of an experiment simply as a process that generates data that will be used to help make some decision</red> 

- From this definition we see that we are surrounded by experiments

    + The time required for a computer to boot up each morning
    + The result of a coin flip
    + The result of rolling a die

- As an analyst, you likely won't be involved in the experiment - instead, you may be asked to analyze some data that had already been collected

- Understanding the type of data generated by an experiment and the manner in which the data are collected are crucial to selecting a valid approach  best to model the data   

```{block, echo=F}
IN SOME CASES YOU ARE PART OF AN EXPERIMENT

Need to discuss the work to set up an experiment make sure data supports the decision to be made or hypothesis to be tested

As analyst 

- may be asked to design experiment to collect data used to make decision
- May be asked to use already collected data to determine which decision to make (more common situation)

- Often data is collected without fully understanding the experiments that will be used or the the experiments change over time and the data collected does not provide sufficient infor to answer new questions 
```

- For the rest of this lecture we'll use a simple experiment in which we roll a 6-sided die one or more times

## Outcomes

- An outcome is any result that could <u>possibly</u> be observed from an experiment

    + If our experiment involved a single roll of a 6-sided die, it is trivial to say that the possible outcomes are $\{1\}$, $\{2\}$, $\{3\}$, $\{4\}$, $\{5\}$, or $\{6\}$
    + Similarly we understand that an impossible outcome would be any number that is not an integer and any integer that is either less than zero or greater that 7
    + Note that each outcome is enclosed within curly brackets 

- Suppose, an experiment involves rolling a 6-sided die two times, what would some possible outcomes be?  
    
    + Many times the response is "Any number between 2 and 12" - but this is incorrect
    + This response assumes that I want you to take the result of the two rolls and add them together
    + While I may eventually ask you to do this, this is not the same as the possible outcomes 
    + some possible outcomes would be $\{1,5\}$, $\{3,1\}$, or $\{6,6\}$. An outcome that would not be possible would be $\{7,2\}$.

## Sample space

- The sample space refers to the collection of all possible outcomes that could result from an experiment 

- In the literature the sample space is often denoted by the Greek capital letter omega $\Omega$ or a capital script "S" $\mathcal{S}$

## Events

- An event is a set of outcomes from an experiment (a subset of the sample space) to which a probability can be assigned

- A single outcome may be an element of many different events, and different events in an experiment are usually not equally likely, since they may include very different groups of outcomes

## Random Variable

- Informally, a random variable defined as a variable whose value is random (duh).

- More formally, a random variable is a function that assigns probabilities to events

## Borel Sigma-Algebra

- Represents the mapping of the outcomes to the events

# Statistics Concepts

## Terminology

- Again Statistics is a sub-field of applied mathematics and is concerned with analyzing data 

- More specifically, statistics involves the following tasks

    - Collecting Data 
    - Organizing Data
    - Displaying and Presenting Data
    - Interpreting Data

- Statistical methods are used to make **descriptions** and/or **inferences** about some population

- It's not surprising then that statistical methods used in data analyses are often sub-divided into two classes

    + Descriptive statistical methods
    + Inferential statistical methods

## Distinguishing between **S**tatistics and **s**tatistics

- Before moving forward we need to make a clear distinction between **S**tatistics (big S) and **s**tatistics (little s)

    + **S**tatistics (big S) is a sub-field of applied mathematics and is concerned with analyzing data 
    + **s**tatistics (little s) are numerical quantities calculated from a data set that provide important features about the data

- In this presentation we define a number of descriptive **s**tatistics (little s)

    + Explain what important features they provide to help us understand our data
    + Show how they are calculated
    + Demonstrate how to compute them using R

- The big idea is that descriptive statistics allow us to reduce large data sets down to a few numerical measures - these measures give clues as to how to proceed in an analysis

# Random Samples

```{r, echo=FALSE}
obs_x = "$x_{1},\\ldots,x_{n}$"
rv_X = "$X_1,\\ldots,X_n$"
eq2 = "$F_{_{X}}(x)$"
E_x = "$\\operatorname{E}[x]$"
eq13 = "\\xi = [x_1,\\ldots,x_n]"
eq14 = "$\\Xi = [X_1,\\ldots,X_n]$"
eq15 = "F_{_{\\Xi}}(\\xi) = F_{_{X}}(x_1)\\times\\ldots\\times F_{_{X}}(x_n)"
```

## Defining terms

- The $n$ observations we collect during a test - denoted as $`r eq13`$ - are realizations of random variables `r eq14`

- When a random sample contains $n$ realizations `r obs_x` of $n$ random variables $`r eq13`$ we say that the sample has size $n$ (or that the sample size is $n$) and an individual realization $x_{i}$ is referred to as an observation

<blockquote>
<br>
<br>
<red>Incorrect wording:</red> $n$ independent realizations of the random variable $X$
<br>
<br>
<green>Correct wording:</green> realizations of $n$ independent random variables `r rv_X`
</blockquote>

- In the simplest case the random variables `r rv_X` are independent and have a common distribution function `r eq2` and we say that `r rv_X` are independent and indentically distributed, or IID

- IID Example

    + The lifetime of our widgets is represented by the random variable $X$, whose distribution function `r eq2` is unknown. 
    + Suppose we independently observe the lifetimes of $10$ widgets and denote these realizations by $x_{1},x_{2},\ldots,x_{10}$
    + We're interested in the expected value of $X$, which is an unknown characteristic of `r eq2`
    + We infer `r E_x` from the data, and estimate `r E_x` with the sample mean $\bar{x} = \sum_{i = 1}^{10} x_i/10$
    + The observed data $x_{1},x_{2},\ldots,x_{10}$ constitute our sample and `r E_x` is the quantity about which we are making a statistical inference

- While in the simplest case `r rv_X` are independent random variables, more complicated cases are possible

    + `r rv_X` are not independent
    + `r rv_X` are random vectors having a common joint distribution function
    + `r rv_X` do not have a common probability distribution

- In a more general sense we say: _A sample $\xi$ is the realization of a random vector $\Xi$_

- The distribution function of $\Xi$, denoted by $F_{_{\Xi}}(\xi)$, is the unknown distribution function that constitutes the object of inference

- Therefore, "sample" is just a synonym of "realization of a random vector". The following examples show how this general definition accommodates the special cases mentioned above

## Example 1: Independent and Identically Distributed

- We observe $n$ realizations `r obs_x` of $n$ independent random variables `r rv_X` having a common distribution function `r eq2`

- The sample is the $n$-dimensional vector $`r eq13`$, which is a realization of the random vector `r eq14`

- The joint distribution function of $\Xi$ is 

$$
`r eq15`
$$

## Example 2: Identically Distributed, but not Independent

- We observe $n$ realizations `r obs_x` of $n$ random variables `r rv_X` that are not independent but have a common distribution function `r eq2`

- The sample is again the $n$-dimensional vector $`r eq13`$, which is a realization of the random vector `r eq14`

- However, in this case the joint distribution function $F_{_{\Xi}}(\xi)$ can no longer be written as the product of the distribution functions of `r rv_X`
